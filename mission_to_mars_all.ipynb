{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  'https://mars.nasa.gov/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "# print(soup.prettify())\n",
    "# Pull the most recent news articles\n",
    "result = soup.find('ul', class_='item_list')\n",
    "\n",
    "# Extract the most recent news' title and content\n",
    "news_title = result.find('li', class_=\"content_title\").find('a').text\n",
    "news_p = result.find('li', class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-637bcb20cd01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Extract the most recent article's title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnews_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'li'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"content_title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Extract the most recent article's description\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "# Pull the most recent news info\n",
    "def scrape_nasa_news():\n",
    "    news = {}\n",
    "    url =  'https://mars.nasa.gov/news'\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    result = soup.find('ul', class_='item_list')\n",
    "\n",
    "    # Extract the most recent news' title and content\n",
    "    news_title = result.find('li', class_=\"content_title\").find('a').text\n",
    "    news_p = result.find('li', class_=\"article_teaser_body\").text\n",
    "    news[\"news_title\"] = news_title\n",
    "    news[\"news_p\"] = news_p\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we were to hold more than one news\n",
    "news_list = []\n",
    "url =  'https://mars.nasa.gov/news'\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "results = soup.find_all('li', class_=\"slide\")\n",
    "results\n",
    "\n",
    "for result in results:\n",
    "    news = {}\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "        news_title = result.find('li', class_=\"content_title\").find('a').text\n",
    "        # Identify and return text of listing\n",
    "        news_p = result.find('li', class_=\"article_teaser_body\").text\n",
    "        # Print results only if title, price, and link are available\n",
    "        if (news_title and news_p ):\n",
    "            news[\"news_title\"] = news_title\n",
    "            news[\"news_p\"] = news_p\n",
    "            news_list.append(news)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': 'Opportunity Hunkers Down During Dust Storm',\n",
       " 'news_p': \"It's the beginning of the end for the planet-encircling dust storm on Mars. But it could still be weeks, or even months, before skies are clear enough for NASA's Opportunity rover to recharge its batteries and phone home.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_nasa_news():\n",
    "    news = {}\n",
    "    url =  'https://mars.nasa.gov/news'\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    # result = soup.find('li', class_='slide')\n",
    "    result = soup.find('div', class_='slide')\n",
    "    # Extract the most recent news' title and content\n",
    "    # news_title = result.find('li', class_=\"content_title\").find('a').text\n",
    "    news_title = result.find('div', class_=\"content_title\").find('a').text.strip()\n",
    "    # news_p = result.find('li', class_=\"article_teaser_body\").text\n",
    "    news_p = result.a.text.strip()\n",
    "    news[\"news_title\"] = news_title\n",
    "    news[\"news_p\"] = news_p\n",
    "    return news\n",
    "scrape_nasa_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19323_ip.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the featured image\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "base_url =\"https://www.jpl.nasa.gov\"\n",
    "    \n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "article = soup.find(\"article\")\n",
    "\n",
    "featured_img_url = base_url + article.a['data-fancybox-href']\n",
    "featured_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is one at a time\n",
    "def scrape_featured_image():\n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    base_url =\"https://www.jpl.nasa.gov\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    article = soup.find(\"article\")\n",
    "\n",
    "    featured_img_url = base_url + article.a['data-fancybox-href']\n",
    "    return featured_img_url\n",
    "\n",
    "#if there were more than one and descriptions needed\n",
    "def scrape_featured_images():\n",
    "    img_info = {}\n",
    "    \n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    base_url =\"https://www.jpl.nasa.gov\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    \n",
    "    title = soup.find('title').string\n",
    "    img_info['title'] = title\n",
    "    \n",
    "    articles = soup.find_all(\"article\")\n",
    "    for article in articles:\n",
    "        img_info['featured-image_description'] = article.a['data-description']\n",
    "        img_info['featured-image-url'] = base_url + article.a['data-fancybox-href']\n",
    "   \n",
    "    return img_info\n",
    "#scrape_featured_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 2227 (2018-11-11), high -3C/26F, low -72C/-97F, pressure at 8.63 hPa, daylight 06:21-18:38'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape latest mars_weather twit\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "    \n",
    "mars_weather = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")[0].text\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_latest_twitt():\n",
    "    url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    \n",
    "    mars_weather = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")[0].text\n",
    "    \n",
    "    return mars_weather\n",
    "\n",
    "# if we were to extract more than one\n",
    "def scrape_twitter():\n",
    "    surf_data = {}\n",
    "    \n",
    "    url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    twit_base_url = \"https://twitter.com\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    \n",
    "    title = soup.find('title').string\n",
    "    surf_data['title'] = title\n",
    "    \n",
    "    weather_tweets = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "    num=0\n",
    "    for tweet in weather_tweets:\n",
    "        #print(str(num))\n",
    "        if num < 1:\n",
    "            # print(tweet.prettify())\n",
    "            latest_weather = tweet.get_text()\n",
    "            surf_data['latest_weather'] = latest_weather\n",
    "        num=num+1\n",
    "        \n",
    "    return surf_data\n",
    "# scrape_latest_twitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                      0                              1\n",
       " 0  Equatorial Diameter:                       6,792 km\n",
       " 1       Polar Diameter:                       6,752 km\n",
       " 2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       " 3                Moons:            2 (Phobos & Deimos)\n",
       " 4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
       " 5         Orbit Period:           687 days (1.9 years)\n",
       " 6  Surface Temperature:                  -153 to 20 °C\n",
       " 7         First Record:              2nd millennium BC\n",
       " 8          Recorded By:           Egyptian astronomers]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars Facts\n",
    "import pandas as pd\n",
    "url = 'http://space-facts.com/mars/'\n",
    "# Use Panda's `read_html` to parse the url\n",
    "tables = pd.read_html(url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter:</th>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              value\n",
       "description                                        \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.42 x 10^23 kg (10.7% Earth)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.52 AU)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tables[0]\n",
    "df.columns = ['description', 'value']\n",
    "df.set_index('description', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>value</th>    </tr>    <tr>      <th>description</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Equatorial Diameter:</th>      <td>6,792 km</td>    </tr>    <tr>      <th>Polar Diameter:</th>      <td>6,752 km</td>    </tr>    <tr>      <th>Mass:</th>      <td>6.42 x 10^23 kg (10.7% Earth)</td>    </tr>    <tr>      <th>Moons:</th>      <td>2 (Phobos &amp; Deimos)</td>    </tr>    <tr>      <th>Orbit Distance:</th>      <td>227,943,824 km (1.52 AU)</td>    </tr>    <tr>      <th>Orbit Period:</th>      <td>687 days (1.9 years)</td>    </tr>    <tr>      <th>Surface Temperature:</th>      <td>-153 to 20 °C</td>    </tr>    <tr>      <th>First Record:</th>      <td>2nd millennium BC</td>    </tr>    <tr>      <th>Recorded By:</th>      <td>Egyptian astronomers</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Pandas to convert the data to a HTML table string\n",
    "html_table = df.to_html()\n",
    "html_table = html_table.replace('\\n', '')\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].to_html('table.html')\n",
    "!explorer table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_mars_facts():\n",
    "    url = 'http://space-facts.com/mars/'\n",
    "    # Use Panda's `read_html` to parse the url\n",
    "    tables = pd.read_html(url)\n",
    "    df = tables[0]\n",
    "    df.columns = ['description', 'value']\n",
    "    df.set_index('description', inplace=True)\n",
    "    return df.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cerberus Hemisphere Enhanced',\n",
       " 'Schiaparelli Hemisphere Enhanced',\n",
       " 'Syrtis Major Hemisphere Enhanced',\n",
       " 'Valles Marineris Hemisphere Enhanced']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "# Initialize an empty list that will be filled with dictionaries\n",
    "# Initialize a list of the hemispheres so we can loop through and do everything in one cell\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "hemispheres = []\n",
    "results = soup.find_all(\"div\", class_=\"description\")\n",
    "\n",
    "for result in results:\n",
    "    hemispheres.append(result.h3.text)\n",
    "    \n",
    "# hemispheres = ['Cerberus', 'Schiaparelli', 'Syrtis Major', 'Valles Marineris']\n",
    "hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls = []\n",
    "for hemi in hemispheres:\n",
    "    # Send the browser to the USGS Astrogeology site to get high res images of the hemispheres\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Do the same as above for Schiaparelli Hemisphere\n",
    "    browser.click_link_by_partial_text(f'{hemi}')\n",
    "\n",
    "    # create HTML object\n",
    "    html = browser.html\n",
    "\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Initialize the dict\n",
    "    hemi_dict = {}\n",
    "\n",
    "    # Scrape the incomplete URL\n",
    "    inc_url = soup.find('img', class_='wide-image')['src']\n",
    "\n",
    "    # Construct the complete URL\n",
    "    img_url = 'https://astrogeology.usgs.gov' + inc_url\n",
    "\n",
    "    # Store the data in a dictionary then add that dictionary to the tracking list\n",
    "    hemi_dict[\"title\"] = f'{hemi} Hemisphere'\n",
    "    hemi_dict[\"img_url\"] = img_url\n",
    "    hemisphere_image_urls.append(hemi_dict)\n",
    "browser.quit()\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solved as a function - not complete\n",
    "def scrape_mars_hemispheres():\n",
    "    hemisphere_data = {}\n",
    "    \n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    base_url='https://astrogeology.usgs.gov'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    mars_hemispheres = soup.find_all(\"a\",class_='item product-item')\n",
    "    num=0\n",
    "    for hemis in mars_hemispheres:\n",
    "        full_href = base_url+hemis['href']\n",
    "        title = hemis.h3.text\n",
    "        desc = hemis.text\n",
    "        #print(astros.prettify())\n",
    "        #surf_data[] = desc\n",
    "        hemisphere_data[title] = full_href\n",
    "    return hemisphere_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hemispheres():\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "\n",
    "    hemispheres = []\n",
    "    results = soup.find_all(\"div\", class_=\"description\")\n",
    "\n",
    "    for result in results:\n",
    "        hemispheres.append(result.h3.text)\n",
    "\n",
    "    # hemispheres = ['Cerberus', 'Schiaparelli', 'Syrtis Major', 'Valles Marineris']\n",
    "    return hemispheres\n",
    "\n",
    "def scrape_hemisphere_info():\n",
    "    hemispheres = scrape_hemispheres()\n",
    "    hemisphere_info = []\n",
    "    \n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    \n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "        \n",
    "    for hemi in hemispheres:\n",
    "        #  Hemisphere\n",
    "        browser.click_link_by_partial_text(f'{hemi}')\n",
    "\n",
    "        # create HTML object, Parse HTML with Beautiful Soup\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        # Initialize the dict\n",
    "        hemi_dict = {}\n",
    "        # Scrape the incomplete URL\n",
    "        inc_url = soup.find('img', class_='wide-image')['src']\n",
    "        # Construct the complete URL\n",
    "        img_url = 'https://astrogeology.usgs.gov' + inc_url\n",
    "        # Store the data in a dictionary then add that dictionary to the tracking list\n",
    "        hemi_dict[\"title\"] = f'{hemi}'\n",
    "        hemi_dict[\"img_url\"] = img_url\n",
    "        hemisphere_info.append(hemi_dict)\n",
    "        \n",
    "        # Return to the original page\n",
    "        browser.click_link_by_partial_text('Back')\n",
    "        \n",
    "    browser.quit()\n",
    "    return hemisphere_info\n",
    "#scrape_hemisphere_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': 'Opportunity Hunkers Down During Dust Storm',\n",
       " 'news_p': \"It's the beginning of the end for the planet-encircling dust storm on Mars. But it could still be weeks, or even months, before skies are clear enough for NASA's Opportunity rover to recharge its batteries and phone home.\",\n",
       " 'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA07137_ip.jpg',\n",
       " 'mars_weather': 'Sol 2227 (2018-11-11), high -3C/26F, low -72C/-97F, pressure at 8.63 hPa, daylight 06:21-18:38',\n",
       " 'mars_facts_table': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>value</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'hemisphere_info': [{'title': 'Cerberus Hemisphere Enhanced',\n",
       "   'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       "  {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "   'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       "  {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "   'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       "  {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "   'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape():\n",
    "    mars_facts = {}\n",
    "    mars_facts[\"news_title\"] = scrape_nasa_news()[\"news_title\"]\n",
    "    mars_facts[\"news_p\"] = scrape_nasa_news()[\"news_p\"]\n",
    "    mars_facts[\"featured_image_url\"] = scrape_featured_image()\n",
    "    mars_facts[\"mars_weather\"] = scrape_latest_twitt()\n",
    "    mars_facts[\"mars_facts_table\"] = scrape_mars_facts()\n",
    "    mars_facts[\"hemisphere_info\"] = scrape_hemisphere_info()\n",
    "    # Return the dictionary\n",
    "    return mars_facts\n",
    "scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
